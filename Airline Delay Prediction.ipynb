{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airline Delay Prediction using PySpark, PandasUDF and Scikit-Learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from pyspark.sql.functions import pandas_udf, struct, PandasUDFType\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('C:/Users/Devanshi/Desktop/All recent required folders/Airline Delay Prediction/data/All origins.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DELAYED'] = np.where(df['DEP_DELAY']> 10, 1, 0)\n",
    "df = df.drop(['YEAR','ORIGIN_CITY_NAME','ORIGIN','DEST','ORIGIN_STATE_NM','CANCELLED','DEST_CITY_NAME',\n",
    "       'DEST_STATE_NM', 'DEP_TIME','DEP_DELAY', 'ARR_TIME', 'ARR_DELAY'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'DISTANCE', 'CARRIER_DELAY',\n",
       "       'WEATHER_DELAY', 'NAS_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
       "       'id', 'DELAYED'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "StructField('id', IntegerType()),\n",
    "StructField('recall', FloatType()),\n",
    "StructField('precision', FloatType()),\n",
    "StructField('accuracy', FloatType()),\n",
    "StructField('auc', FloatType())\n",
    "])\n",
    "X_columns = df.drop(columns = ['id', 'DELAYED']).columns\n",
    "y_columns = 'DELAYED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "def model_results_per_id_rf(df):\n",
    "    id = int(df.id.unique()[0])\n",
    "    X = df[X_columns]\n",
    "    y = df[y_columns]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "    steps = [('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(random_state=0, n_jobs=-1))\n",
    "    ]\n",
    "    pipeline = Pipeline(steps)\n",
    "    param_distributions = {'rf__n_estimators': [50,100],'rf__min_samples_leaf': [1, 2, 4],'rf__max_depth': [5,10,20]}\n",
    "    rf_cv = RandomizedSearchCV(pipeline, param_distributions, cv = 5, n_jobs = -1, scoring = 'f1')\n",
    "    rf_cv.fit(X_train, y_train)\n",
    "    y_pred = rf_cv.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred).tolist()\n",
    "    precision = precision_score(y_test, y_pred).tolist()\n",
    "    recall = recall_score(y_test, y_pred).tolist()\n",
    "    y_pred_prob = rf_cv.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, y_pred_prob).tolist()\n",
    "    model_results = pd.DataFrame([[id, recall, precision, accuracy, auc]], columns = ['id', 'recall', 'precision', 'accuracy', 'auc'])\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\opt\\spark\\spark-3.0.1-bin-hadoop2.7\\python\\pyspark\\sql\\pandas\\group_ops.py:73: UserWarning: It is preferred to use 'applyInPandas' over this API. This API will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_results_by_id1 = df_spark.groupBy('id').apply(model_results_per_id_rf).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.2 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  recall  precision  accuracy    auc\n",
       "0   1   0.650      0.979     0.927  0.869\n",
       "1   2   0.728      0.973     0.945  0.888\n",
       "2   3   0.692      0.987     0.931  0.884\n",
       "3   4   0.714      0.973     0.936  0.894"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_results_by_id1[['recall', 'precision', 'accuracy', 'auc']] = model_results_by_id1[['recall', 'precision', 'accuracy', 'auc']].round(3)\n",
    "model_results_by_id1.sort_values(by = 'id').reset_index(drop = True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "def model_results_per_id_svm1(df):\n",
    "    id = int(df.id.unique()[0])\n",
    "    X = df[X_columns]\n",
    "    y = df[y_columns]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 0)\n",
    "    svm = LinearSVC(C=5, random_state = 67)\n",
    "    clf = CalibratedClassifierCV(svm) \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred).tolist()\n",
    "    precision = precision_score(y_test, y_pred).tolist()\n",
    "    recall = recall_score(y_test, y_pred).tolist()\n",
    "    y_pred_prob = clf.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, y_pred_prob).tolist()\n",
    "    model_results = pd.DataFrame([[id, recall, precision, accuracy, auc]], columns = ['id', 'recall', 'precision', 'accuracy', 'auc'])\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\opt\\spark\\spark-3.0.1-bin-hadoop2.7\\python\\pyspark\\sql\\pandas\\group_ops.py:73: UserWarning: It is preferred to use 'applyInPandas' over this API. This API will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_results_by_id2a = df_spark.groupBy('id').apply(model_results_per_id_svm1).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.231</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  recall  precision  accuracy    auc\n",
       "0   1   0.174      0.999     0.835  0.819\n",
       "1   2   0.268      0.999     0.864  0.863\n",
       "2   3   0.300      1.000     0.847  0.828\n",
       "3   4   0.231      1.000     0.837  0.858"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_results_by_id2a[['recall', 'precision', 'accuracy', 'auc']] = model_results_by_id2a[['recall', 'precision', 'accuracy', 'auc']].round(3)\n",
    "model_results_by_id2a.sort_values(by = 'id').reset_index(drop = True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "def model_results_per_id_svm2(df):\n",
    "    id = int(df.id.unique()[0])\n",
    "    X = df[X_columns]\n",
    "    y = df[y_columns]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 0)\n",
    "    svm = LinearSVC(C=5, random_state = 67)\n",
    "    clf = CalibratedClassifierCV(svm, method='isotonic') \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred).tolist()\n",
    "    precision = precision_score(y_test, y_pred).tolist()\n",
    "    recall = recall_score(y_test, y_pred).tolist()\n",
    "    y_pred_prob = clf.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, y_pred_prob).tolist()\n",
    "    model_results = pd.DataFrame([[id, recall, precision, accuracy, auc]], columns = ['id', 'recall', 'precision', 'accuracy', 'auc'])\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\opt\\spark\\spark-3.0.1-bin-hadoop2.7\\python\\pyspark\\sql\\pandas\\group_ops.py:73: UserWarning: It is preferred to use 'applyInPandas' over this API. This API will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_results_by_id2b = df_spark.groupBy('id').apply(model_results_per_id_svm2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.96 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  recall  precision  accuracy    auc\n",
       "0   1   0.642      0.972     0.925  0.836\n",
       "1   2   0.720      0.958     0.942  0.869\n",
       "2   3   0.675      0.979     0.926  0.849\n",
       "3   4   0.709      0.952     0.931  0.864"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_results_by_id2b[['recall', 'precision', 'accuracy', 'auc']] = model_results_by_id2b[['recall', 'precision', 'accuracy', 'auc']].round(3)\n",
    "model_results_by_id2b.sort_values(by = 'id').reset_index(drop = True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "def model_results_per_id_lr(df):\n",
    "    id = int(df.id.unique()[0])\n",
    "    X = df[X_columns]\n",
    "    y = df[y_columns]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 0)\n",
    "    clf = LogisticRegression(max_iter=1000, C=100).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred).tolist()\n",
    "    precision = precision_score(y_test, y_pred).tolist()\n",
    "    recall = recall_score(y_test, y_pred).tolist()\n",
    "    y_pred_prob = clf.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, y_pred_prob).tolist()\n",
    "    model_results = pd.DataFrame([[id, recall, precision, accuracy, auc]], columns = ['id', 'recall', 'precision', 'accuracy', 'auc'])\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\opt\\spark\\spark-3.0.1-bin-hadoop2.7\\python\\pyspark\\sql\\pandas\\group_ops.py:73: UserWarning: It is preferred to use 'applyInPandas' over this API. This API will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_results_by_id3 = df_spark.groupBy('id').apply(model_results_per_id_lr).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.96 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  recall  precision  accuracy    auc\n",
       "0   1   0.644      0.959     0.923  0.852\n",
       "1   2   0.714      0.968     0.943  0.877\n",
       "2   3   0.682      0.966     0.925  0.867\n",
       "3   4   0.706      0.958     0.931  0.877"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_results_by_id3[['recall', 'precision', 'accuracy', 'auc']] = model_results_by_id3[['recall', 'precision', 'accuracy', 'auc']].round(3)\n",
    "model_results_by_id3.sort_values(by = 'id').reset_index(drop = True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
